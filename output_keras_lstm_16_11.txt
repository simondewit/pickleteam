Train on 482823 samples, validate on 50000 samples
Epoch 1/6
482823/482823 [==============================] - 4459s 9ms/step - loss: 1.8953 - acc: 0.4301 - val_loss: 2.2566 - val_acc: 0.2995
Epoch 2/6
482823/482823 [==============================] - 4454s 9ms/step - loss: 1.6106 - acc: 0.5064 - val_loss: 2.1280 - val_acc: 0.3588
Epoch 3/6
482823/482823 [==============================] - 4452s 9ms/step - loss: 1.2160 - acc: 0.6286 - val_loss: 2.1233 - val_acc: 0.3992
Epoch 4/6
482823/482823 [==============================] - 4453s 9ms/step - loss: 1.0143 - acc: 0.6876 - val_loss: 2.2259 - val_acc: 0.4140
Epoch 5/6
482823/482823 [==============================] - 4456s 9ms/step - loss: 0.9133 - acc: 0.7143 - val_loss: 2.2802 - val_acc: 0.4266
Epoch 6/6
482823/482823 [==============================] - 4457s 9ms/step - loss: 0.8405 - acc: 0.7350 - val_loss: 2.3286 - val_acc: 0.4358
50000/50000 [==============================] - 159s 3ms/step


precision sklearn: 0.47
recall sklearn: 0.444
fscore sklearn: 0.427

Class    Precision       Recall          F-score
0        0.773           0.211           0.332
1        0.333           0.628           0.435
2        0.566           0.667           0.612
3        0.249           0.492           0.331
4        0.585           0.662           0.621
5        0.337           0.374           0.355
6        0.315           0.405           0.354
7        0.426           0.451           0.438
8        0.379           0.359           0.369
9        0.317           0.359           0.337
10       0.671           0.371           0.44
11       0.712           0.456           0.504
12       0.792           0.154           0.253
13       0.596           0.236           0.326
14       0.58            0.26            0.338
15       0.597           0.329           0.383
16       0.603           0.24            0.332
17       0.702           0.513           0.522
18       0.62            0.384           0.42
19       0.555           0.249           0.321
       0       1       2       3       4       5       6       7       8       9      10      11      12      13      14      15      16      17      18      19
0     0.21    0.23    0.04    0.19    0.02    0.04    0.03    0.03    0.04    0.05    0.01    0.01    0.00    0.02    0.01    0.01    0.01    0.02    0.01    0.01
1     0.02    0.63    0.05    0.07    0.02    0.03    0.03    0.02    0.02    0.02    0.01    0.01    0.00    0.01    0.01    0.01    0.01    0.01    0.01    0.01
2     0.01    0.08    0.67    0.02    0.03    0.03    0.03    0.01    0.01    0.01    0.01    0.01    0.00    0.00    0.02    0.02    0.01    0.01    0.01    0.02
3     0.03    0.18    0.04    0.49    0.02    0.04    0.02    0.03    0.04    0.04    0.01    0.01    0.00    0.01    0.01    0.01    0.00    0.01    0.01    0.01
4     0.01    0.07    0.06    0.02    0.66    0.01    0.04    0.02    0.01    0.01    0.01    0.01    0.00    0.00    0.01    0.03    0.01    0.01    0.02    0.01
5     0.02    0.16    0.10    0.09    0.02    0.37    0.04    0.03    0.02    0.03    0.01    0.01    0.00    0.01    0.02    0.02    0.02    0.02    0.01    0.02
6     0.02    0.14    0.10    0.04    0.04    0.05    0.40    0.03    0.02    0.02    0.01    0.02    0.00    0.00    0.02    0.03    0.01    0.01    0.01    0.02
7     0.01    0.16    0.03    0.07    0.04    0.04    0.03    0.45    0.01    0.01    0.01    0.01    0.00    0.01    0.02    0.02    0.01    0.03    0.02    0.01
8     0.02    0.17    0.04    0.18    0.02    0.03    0.03    0.03    0.36    0.03    0.01    0.02    0.00    0.02    0.01    0.01    0.01    0.01    0.01    0.01
9     0.03    0.17    0.05    0.14    0.02    0.05    0.03    0.02    0.03    0.36    0.01    0.01    0.00    0.01    0.02    0.01    0.01    0.01    0.02    0.01
10    0.01    0.07    0.03    0.02    0.03    0.01    0.04    0.02    0.01    0.01    0.53    0.01    0.00    0.00    0.01    0.01    0.00    0.00    0.17    0.01
11    0.01    0.08    0.03    0.02    0.02    0.01    0.03    0.02    0.01    0.01    0.01    0.70    0.00    0.00    0.01    0.01    0.00    0.01    0.01    0.01
12    0.07    0.16    0.03    0.08    0.03    0.08    0.22    0.05    0.04    0.02    0.03    0.02    0.10    0.01    0.02    0.01    0.00    0.01    0.02    0.02
13    0.03    0.18    0.03    0.23    0.02    0.03    0.02    0.02    0.04    0.04    0.01    0.01    0.00    0.26    0.01    0.01    0.01    0.01    0.01    0.02
14    0.01    0.16    0.14    0.05    0.02    0.06    0.06    0.02    0.02    0.03    0.01    0.01    0.00    0.01    0.31    0.02    0.02    0.01    0.02    0.03
15    0.01    0.08    0.13    0.03    0.08    0.02    0.06    0.02    0.02    0.01    0.01    0.01    0.00    0.01    0.01    0.45    0.00    0.01    0.02    0.01
16    0.01    0.18    0.16    0.04    0.02    0.09    0.04    0.02    0.02    0.03    0.01    0.01    0.00    0.01    0.02    0.01    0.27    0.02    0.01    0.03
17    0.01    0.04    0.02    0.03    0.01    0.02    0.01    0.02    0.00    0.00    0.00    0.00    0.00    0.00    0.01    0.00    0.00    0.82    0.00    0.00
18    0.01    0.06    0.05    0.01    0.03    0.02    0.04    0.03    0.01    0.01    0.11    0.01    0.00    0.00    0.01    0.02    0.01    0.00    0.56    0.01
19    0.01    0.13    0.16    0.07    0.04    0.05    0.06    0.02    0.01    0.02    0.01    0.01    0.00    0.01    0.04    0.02    0.02    0.01    0.02    0.29